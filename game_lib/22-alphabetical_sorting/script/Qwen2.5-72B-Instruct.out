INFO 03-02 08:20:08 __init__.py:207] Automatically detected platform cuda.
INFO 03-02 08:20:09 api_server.py:912] vLLM API server version 0.7.3
INFO 03-02 08:20:09 api_server.py:913] args: Namespace(host=None, port=9004, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='/map-vepfs/models/jiajun/Qwen/Qwen2.5-72B-Instruct', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=15000, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=['Qwen2.5-72B-Instruct'], qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False)
INFO 03-02 08:20:09 api_server.py:209] Started engine process with PID 2598727
INFO 03-02 08:21:36 __init__.py:207] Automatically detected platform cuda.
INFO 03-02 08:21:42 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'classify', 'embed', 'score'}. Defaulting to 'generate'.
INFO 03-02 08:21:43 config.py:1382] Defaulting to use mp for distributed inference
INFO 03-02 08:23:17 config.py:549] This model supports multiple tasks: {'score', 'embed', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 03-02 08:23:17 config.py:1382] Defaulting to use mp for distributed inference
INFO 03-02 08:23:17 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/map-vepfs/models/jiajun/Qwen/Qwen2.5-72B-Instruct', speculative_config=None, tokenizer='/map-vepfs/models/jiajun/Qwen/Qwen2.5-72B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=15000, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen2.5-72B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=True, 
WARNING 03-02 08:23:18 multiproc_worker_utils.py:300] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-02 08:23:18 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:19 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:41 cuda.py:229] Using Flash Attention backend.
INFO 03-02 08:23:41 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:45 utils.py:916] Found nccl from library libnccl.so.2
INFO 03-02 08:23:45 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:45 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 03-02 08:23:45 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:49 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_4,5.json
INFO 03-02 08:23:49 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_4,5.json
INFO 03-02 08:23:49 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_ec4ea3bc'), local_subscribe_port=49375, remote_subscribe_port=None)
INFO 03-02 08:23:49 model_runner.py:1110] Starting to load model /map-vepfs/models/jiajun/Qwen/Qwen2.5-72B-Instruct...
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:23:49 model_runner.py:1110] Starting to load model /map-vepfs/models/jiajun/Qwen/Qwen2.5-72B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/37 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 1/37 [00:09<05:53,  9.81s/it]
Loading safetensors checkpoint shards:   5% Completed | 2/37 [00:18<05:28,  9.40s/it]
Loading safetensors checkpoint shards:   8% Completed | 3/37 [00:34<06:53, 12.16s/it]
Loading safetensors checkpoint shards:  11% Completed | 4/37 [00:43<06:05, 11.07s/it]
Loading safetensors checkpoint shards:  14% Completed | 5/37 [00:51<05:11,  9.74s/it]
Loading safetensors checkpoint shards:  16% Completed | 6/37 [00:59<04:44,  9.17s/it]
Loading safetensors checkpoint shards:  19% Completed | 7/37 [01:13<05:28, 10.95s/it]
Loading safetensors checkpoint shards:  22% Completed | 8/37 [01:22<04:55, 10.19s/it]
Loading safetensors checkpoint shards:  24% Completed | 9/37 [01:31<04:39, 10.00s/it]
Loading safetensors checkpoint shards:  27% Completed | 10/37 [01:40<04:19,  9.60s/it]
Loading safetensors checkpoint shards:  30% Completed | 11/37 [01:48<03:54,  9.00s/it]
Loading safetensors checkpoint shards:  32% Completed | 12/37 [01:55<03:31,  8.48s/it]
Loading safetensors checkpoint shards:  35% Completed | 13/37 [02:02<03:13,  8.08s/it]
Loading safetensors checkpoint shards:  38% Completed | 14/37 [02:10<03:01,  7.88s/it]
Loading safetensors checkpoint shards:  41% Completed | 15/37 [02:16<02:46,  7.55s/it]
Loading safetensors checkpoint shards:  43% Completed | 16/37 [02:23<02:31,  7.21s/it]
Loading safetensors checkpoint shards:  46% Completed | 17/37 [02:30<02:20,  7.04s/it]
Loading safetensors checkpoint shards:  49% Completed | 18/37 [02:40<02:33,  8.07s/it]
Loading safetensors checkpoint shards:  51% Completed | 19/37 [02:47<02:19,  7.75s/it]
Loading safetensors checkpoint shards:  54% Completed | 20/37 [02:54<02:05,  7.39s/it]
Loading safetensors checkpoint shards:  57% Completed | 21/37 [02:59<01:50,  6.89s/it]
Loading safetensors checkpoint shards:  59% Completed | 22/37 [03:10<01:58,  7.91s/it]
Loading safetensors checkpoint shards:  62% Completed | 23/37 [03:17<01:48,  7.71s/it]
Loading safetensors checkpoint shards:  65% Completed | 24/37 [03:24<01:37,  7.51s/it]
Loading safetensors checkpoint shards:  68% Completed | 25/37 [03:31<01:29,  7.46s/it]
Loading safetensors checkpoint shards:  70% Completed | 26/37 [03:41<01:31,  8.29s/it]
Loading safetensors checkpoint shards:  73% Completed | 27/37 [03:49<01:19,  8.00s/it]
Loading safetensors checkpoint shards:  76% Completed | 28/37 [03:56<01:09,  7.71s/it]
Loading safetensors checkpoint shards:  78% Completed | 29/37 [04:03<01:00,  7.60s/it]
Loading safetensors checkpoint shards:  81% Completed | 30/37 [04:10<00:51,  7.43s/it]
Loading safetensors checkpoint shards:  84% Completed | 31/37 [04:18<00:44,  7.46s/it]
Loading safetensors checkpoint shards:  86% Completed | 32/37 [04:25<00:36,  7.30s/it]
Loading safetensors checkpoint shards:  89% Completed | 33/37 [04:31<00:28,  7.10s/it]
Loading safetensors checkpoint shards:  92% Completed | 34/37 [04:39<00:21,  7.21s/it]
Loading safetensors checkpoint shards:  95% Completed | 35/37 [04:46<00:14,  7.22s/it]
Loading safetensors checkpoint shards:  97% Completed | 36/37 [04:53<00:07,  7.05s/it]
Loading safetensors checkpoint shards: 100% Completed | 37/37 [04:59<00:00,  6.97s/it]
Loading safetensors checkpoint shards: 100% Completed | 37/37 [04:59<00:00,  8.11s/it]

INFO 03-02 08:28:53 model_runner.py:1115] Loading model weights took 67.8002 GB
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:28:53 model_runner.py:1115] Loading model weights took 67.8002 GB
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:04 worker.py:267] Memory profiling takes 10.77 seconds
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:04 worker.py:267] the current vLLM instance can use total_gpu_memory (79.35GiB) x gpu_memory_utilization (0.95) = 75.38GiB
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:04 worker.py:267] model weights take 67.80GiB; non_torch_memory takes 1.02GiB; PyTorch activation peak memory takes 2.39GiB; the rest of the memory reserved for KV Cache is 4.17GiB.
INFO 03-02 08:29:04 worker.py:267] Memory profiling takes 10.93 seconds
INFO 03-02 08:29:04 worker.py:267] the current vLLM instance can use total_gpu_memory (79.35GiB) x gpu_memory_utilization (0.95) = 75.38GiB
INFO 03-02 08:29:04 worker.py:267] model weights take 67.80GiB; non_torch_memory takes 1.02GiB; PyTorch activation peak memory takes 2.39GiB; the rest of the memory reserved for KV Cache is 4.17GiB.
INFO 03-02 08:29:04 executor_base.py:111] # cuda blocks: 1708, # CPU blocks: 1638
INFO 03-02 08:29:04 executor_base.py:116] Maximum concurrency for 15000 tokens per request: 1.82x
INFO 03-02 08:29:08 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s][1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:08 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:33,  1.02it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:30,  1.09it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:02<00:30,  1.04it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:03<00:28,  1.10it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:04<00:25,  1.17it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:05<00:24,  1.20it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:05<00:22,  1.24it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:06<00:21,  1.28it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:07<00:19,  1.31it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:08<00:18,  1.33it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:08<00:17,  1.35it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:09<00:16,  1.37it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:10<00:16,  1.37it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:11<00:15,  1.36it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:11<00:14,  1.37it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:12<00:13,  1.36it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:13<00:12,  1.40it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:13<00:12,  1.40it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:14<00:11,  1.42it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:15<00:10,  1.45it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:15<00:09,  1.47it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:16<00:08,  1.45it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:17<00:08,  1.44it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:18<00:07,  1.45it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:18<00:07,  1.42it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:19<00:06,  1.44it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:20<00:05,  1.45it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:20<00:04,  1.49it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:21<00:04,  1.49it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:22<00:03,  1.49it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:22<00:02,  1.49it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:23<00:02,  1.44it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:24<00:01,  1.45it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:24<00:00,  1.47it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:26<00:00,  1.11it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:26<00:00,  1.33it/s]
INFO 03-02 08:29:34 custom_all_reduce.py:226] Registering 5635 cuda graph addresses
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:36 custom_all_reduce.py:226] Registering 5635 cuda graph addresses
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:29:36 model_runner.py:1562] Graph capturing finished in 28 secs, took 0.44 GiB
INFO 03-02 08:29:36 model_runner.py:1562] Graph capturing finished in 28 secs, took 0.44 GiB
INFO 03-02 08:29:36 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 43.11 seconds
INFO 03-02 08:29:36 api_server.py:958] Starting vLLM API server on http://0.0.0.0:9004
INFO 03-02 08:29:36 launcher.py:23] Available routes are:
INFO 03-02 08:29:36 launcher.py:31] Route: /openapi.json, Methods: HEAD, GET
INFO 03-02 08:29:36 launcher.py:31] Route: /docs, Methods: HEAD, GET
INFO 03-02 08:29:36 launcher.py:31] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 03-02 08:29:36 launcher.py:31] Route: /redoc, Methods: HEAD, GET
INFO 03-02 08:29:36 launcher.py:31] Route: /health, Methods: GET
INFO 03-02 08:29:36 launcher.py:31] Route: /ping, Methods: GET, POST
INFO 03-02 08:29:36 launcher.py:31] Route: /tokenize, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /detokenize, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/models, Methods: GET
INFO 03-02 08:29:36 launcher.py:31] Route: /version, Methods: GET
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/chat/completions, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/completions, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/embeddings, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /pooling, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /score, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/score, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /rerank, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v1/rerank, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /v2/rerank, Methods: POST
INFO 03-02 08:29:36 launcher.py:31] Route: /invocations, Methods: POST
INFO:     Started server process [2587568]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 03-02 08:33:19 chat_utils.py:332] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-cf3d97dddbe94010828a56758427eeb2: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\na|r|c\nn|i|h\na|s|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14815, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-b0b4ee2dd23b4a999e82f640f7813984: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nt|e|h\ni|n|t\nc|y|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-836162fe7c574c15b0f6b13927364cb2: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nc|l|a\na|c|s\nl|i|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-cf3d97dddbe94010828a56758427eeb2.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-b0b4ee2dd23b4a999e82f640f7813984.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-836162fe7c574c15b0f6b13927364cb2.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-2655ef68c32948b4ba7f40ce879717b1: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\np|t|e\ni|u|r\nr|c|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-56a4b4819ac243ee8609d51fbe4687b2: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|r|n\ns|p|o\ne|a|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-f8411505145e4283a6ac53b66067c833: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nn|o|i\nb|a|t\nd|u|c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-ae5c57f3eef74f80b6979da21cb0f2fd: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\na|r|y\nt|n|u\nv|o|l\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 logger.py:39] Received request chatcmpl-daa796768ffd436f8a5af01040588b75: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ns|o|a\ns|r|g\ne|r|g\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-2655ef68c32948b4ba7f40ce879717b1.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-56a4b4819ac243ee8609d51fbe4687b2.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-f8411505145e4283a6ac53b66067c833.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-ae5c57f3eef74f80b6979da21cb0f2fd.
INFO 03-02 08:33:19 engine.py:280] Added request chatcmpl-daa796768ffd436f8a5af01040588b75.
INFO 03-02 08:33:21 metrics.py:455] Avg prompt throughput: 296.8 tokens/s, Avg generation throughput: 58.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.
INFO 03-02 08:33:26 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.5 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:41334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:26 logger.py:39] Received request chatcmpl-3280f179b88a4b5ebf949fbdb341d016: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nt|h|o\nr|o|d\ny|x|o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:27 engine.py:280] Added request chatcmpl-3280f179b88a4b5ebf949fbdb341d016.
INFO:     127.0.0.1:41338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:31 logger.py:39] Received request chatcmpl-92029299dae04a388f2e2ba2dac22643: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nr|e|t\nt|w|a\nl|a|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:31 engine.py:280] Added request chatcmpl-92029299dae04a388f2e2ba2dac22643.
INFO 03-02 08:33:31 metrics.py:455] Avg prompt throughput: 74.5 tokens/s, Avg generation throughput: 145.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:33 logger.py:39] Received request chatcmpl-73ae337365294402a2bbb72a1762ab71: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nl|e|n\ne|r|n\np|s|o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:33 engine.py:280] Added request chatcmpl-73ae337365294402a2bbb72a1762ab71.
INFO:     127.0.0.1:41350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:36 logger.py:39] Received request chatcmpl-64dc3d4ba5db4b5fb395db6d21adf601: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|n|g\nn|a|e\ne|k|w\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:36 engine.py:280] Added request chatcmpl-64dc3d4ba5db4b5fb395db6d21adf601.
INFO 03-02 08:33:37 metrics.py:455] Avg prompt throughput: 74.6 tokens/s, Avg generation throughput: 144.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:41364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:40 logger.py:39] Received request chatcmpl-29aca64bddd14b1e9f28af30bc45f30c: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\na|p|s\nl|c|e\nl|o|d\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:40 engine.py:280] Added request chatcmpl-29aca64bddd14b1e9f28af30bc45f30c.
INFO:     127.0.0.1:54404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:41 logger.py:39] Received request chatcmpl-3f55ed850081400583d4abda39e523c8: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ny|n|i\nl|u|f\nm|r|o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:41 engine.py:280] Added request chatcmpl-3f55ed850081400583d4abda39e523c8.
INFO 03-02 08:33:42 metrics.py:455] Avg prompt throughput: 74.1 tokens/s, Avg generation throughput: 144.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:41318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:43 logger.py:39] Received request chatcmpl-faf874c72bcb4a8eb2b620bb55d0d9cf: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|c|n\nu|r|a\ns|s|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:43 engine.py:280] Added request chatcmpl-faf874c72bcb4a8eb2b620bb55d0d9cf.
INFO:     127.0.0.1:41322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:43 logger.py:39] Received request chatcmpl-80ca4a786cde420cb1a69811d8757ecf: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nc|a|k\na|t|e\nr|e|r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:43 engine.py:280] Added request chatcmpl-80ca4a786cde420cb1a69811d8757ecf.
INFO 03-02 08:33:47 metrics.py:455] Avg prompt throughput: 74.2 tokens/s, Avg generation throughput: 144.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO 03-02 08:33:52 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:41346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:33:52 logger.py:39] Received request chatcmpl-4099e3728fee45a1b86070fbf30f212a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\na|l|u\nn|t|m\ns|t|i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:33:52 engine.py:280] Added request chatcmpl-4099e3728fee45a1b86070fbf30f212a.
INFO 03-02 08:33:57 metrics.py:455] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 146.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:00 logger.py:39] Received request chatcmpl-2bdf513b393e4f1ebf4cf24605278978: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\na|t|t\nr|s|h\nl|i|g\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:00 engine.py:280] Added request chatcmpl-2bdf513b393e4f1ebf4cf24605278978.
INFO 03-02 08:34:02 metrics.py:455] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 146.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:41340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:02 logger.py:39] Received request chatcmpl-6d70276b0692429eb84bf81e486eaa28: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nv|e|n\na|e|g\nn|c|e\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:02 engine.py:280] Added request chatcmpl-6d70276b0692429eb84bf81e486eaa28.
INFO 03-02 08:34:07 metrics.py:455] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 146.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34028 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:08 logger.py:39] Received request chatcmpl-598410ddc7ec44fea486f4a4b311b67a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nn|e|f\ns|e|e\ni|v|d\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:08 engine.py:280] Added request chatcmpl-598410ddc7ec44fea486f4a4b311b67a.
INFO 03-02 08:34:08 logger.py:39] Received request chatcmpl-0d85db3f2dda45d08117000c8d04f0eb: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nr|d|e\na|c|h\nl|a|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:08 engine.py:280] Added request chatcmpl-0d85db3f2dda45d08117000c8d04f0eb.
INFO:     127.0.0.1:58636 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:10 logger.py:39] Received request chatcmpl-66ac7f00babf473d8f95fddef4a13ed5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nd|i|n\nr|n|a\no|c|e\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:10 engine.py:280] Added request chatcmpl-66ac7f00babf473d8f95fddef4a13ed5.
INFO 03-02 08:34:12 metrics.py:455] Avg prompt throughput: 111.4 tokens/s, Avg generation throughput: 140.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:58626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:14 logger.py:39] Received request chatcmpl-3601b18b45d143afab81c61d9dba65d2: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nd|e|d\nu|c|t\nn|o|i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:14 engine.py:280] Added request chatcmpl-3601b18b45d143afab81c61d9dba65d2.
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:14 logger.py:39] Received request chatcmpl-cb57d57cdf8e463a96bf108ecec12554: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nm|a|l\nn|a|i\nt|n|g\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:14 engine.py:280] Added request chatcmpl-cb57d57cdf8e463a96bf108ecec12554.
INFO 03-02 08:34:17 metrics.py:455] Avg prompt throughput: 74.8 tokens/s, Avg generation throughput: 144.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:34016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:21 logger.py:39] Received request chatcmpl-e7017234d98e4f07ab3e462dd0501521: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|s|d\nu|h|e\ng|n|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:21 engine.py:280] Added request chatcmpl-e7017234d98e4f07ab3e462dd0501521.
INFO:     127.0.0.1:58646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:21 logger.py:39] Received request chatcmpl-a29f8a2763eb4ca4925f8bcd5e7fe2f3: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|n|t\nn|a|e\nc|h|d\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:21 engine.py:280] Added request chatcmpl-a29f8a2763eb4ca4925f8bcd5e7fe2f3.
INFO 03-02 08:34:22 metrics.py:455] Avg prompt throughput: 74.7 tokens/s, Avg generation throughput: 143.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:51970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:25 logger.py:39] Received request chatcmpl-67855e0c61b0437dac9e9bfa0d1eaeb0: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nm|u|h\ni|a|t\nl|i|e\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:25 engine.py:280] Added request chatcmpl-67855e0c61b0437dac9e9bfa0d1eaeb0.
INFO 03-02 08:34:27 metrics.py:455] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 146.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:27 logger.py:39] Received request chatcmpl-e02e09a6033048f991bccabeb3ec2465: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nc|l|o\nh|w|t\ns|a|h\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:27 engine.py:280] Added request chatcmpl-e02e09a6033048f991bccabeb3ec2465.
INFO:     127.0.0.1:54412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:31 logger.py:39] Received request chatcmpl-f3940376860c48d39b0dda0cced070f4: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|s|i\nf|n|n\ny|e|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:31 engine.py:280] Added request chatcmpl-f3940376860c48d39b0dda0cced070f4.
INFO:     127.0.0.1:47294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:32 logger.py:39] Received request chatcmpl-6db070a8d27e4d8ead8d4d894ae25a1a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nn|o|i\ni|m|t\ng|r|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14815, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:32 engine.py:280] Added request chatcmpl-6db070a8d27e4d8ead8d4d894ae25a1a.
INFO 03-02 08:34:32 metrics.py:455] Avg prompt throughput: 111.0 tokens/s, Avg generation throughput: 141.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:34042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:33 logger.py:39] Received request chatcmpl-0b87c2eeb1d74d3dac4e1ad15de8872e: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|u|q\nt|e|s\no|r|g\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:33 engine.py:280] Added request chatcmpl-0b87c2eeb1d74d3dac4e1ad15de8872e.
INFO:     127.0.0.1:51966 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:35 logger.py:39] Received request chatcmpl-a387f854b7274145ae9f4d2b2de4b4cb: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|t|i\no|n|d\nt|r|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:35 engine.py:280] Added request chatcmpl-a387f854b7274145ae9f4d2b2de4b4cb.
INFO 03-02 08:34:37 metrics.py:455] Avg prompt throughput: 74.3 tokens/s, Avg generation throughput: 145.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47316 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:37 logger.py:39] Received request chatcmpl-3dadf830587a489e8146db8e26023918: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\no|c|e\ns|t|e\ny|s|m\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:37 engine.py:280] Added request chatcmpl-3dadf830587a489e8146db8e26023918.
INFO 03-02 08:34:42 metrics.py:455] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 148.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:43 logger.py:39] Received request chatcmpl-0bee4dec9c6e436e8eabfdccb36d8fdb: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nt|t|a\ne|d|e\nm|p|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:43 engine.py:280] Added request chatcmpl-0bee4dec9c6e436e8eabfdccb36d8fdb.
INFO:     127.0.0.1:53228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:45 logger.py:39] Received request chatcmpl-3e4fba809e7344728488465a61ae3179: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nr|a|y\nt|l|l\nn|e|c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:45 engine.py:280] Added request chatcmpl-3e4fba809e7344728488465a61ae3179.
INFO 03-02 08:34:47 metrics.py:455] Avg prompt throughput: 75.0 tokens/s, Avg generation throughput: 145.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:53218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:51 logger.py:39] Received request chatcmpl-4463bac2ace54e19991d08dd828c893a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|v|r\ns|r|e\nt|e|s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:51 engine.py:280] Added request chatcmpl-4463bac2ace54e19991d08dd828c893a.
INFO 03-02 08:34:52 metrics.py:455] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 147.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:53214 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:53 logger.py:39] Received request chatcmpl-212a891fa4354896af0c6b51e48e3713: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nh|e|m\ne|g|o\nc|i|n\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:53 engine.py:280] Added request chatcmpl-212a891fa4354896af0c6b51e48e3713.
INFO:     127.0.0.1:53236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:55 logger.py:39] Received request chatcmpl-fe1ae6de88bf49bdbfedbb6b296522c8: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ny|t|i\nb|i|l\na|n|i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14815, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:55 engine.py:280] Added request chatcmpl-fe1ae6de88bf49bdbfedbb6b296522c8.
INFO 03-02 08:34:57 metrics.py:455] Avg prompt throughput: 74.0 tokens/s, Avg generation throughput: 143.6 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:59810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:34:59 logger.py:39] Received request chatcmpl-26dd10337c5a4b12836f6a04173743a0: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nr|o|t\ne|f|c\nr|r|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:34:59 engine.py:280] Added request chatcmpl-26dd10337c5a4b12836f6a04173743a0.
INFO 03-02 08:35:02 metrics.py:455] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 146.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 15.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:04 logger.py:39] Received request chatcmpl-d750cd5fb0b449f88b3c44dacb44f68b: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nt|s|i\ni|s|t\nc|t|a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:04 engine.py:280] Added request chatcmpl-d750cd5fb0b449f88b3c44dacb44f68b.
INFO 03-02 08:35:07 metrics.py:455] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 147.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:53250 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:09 logger.py:39] Received request chatcmpl-5b2d6f8848384ffaab3819cb17f945ba: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|d|g\nv|i|n\no|r|p\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:09 engine.py:280] Added request chatcmpl-5b2d6f8848384ffaab3819cb17f945ba.
INFO 03-02 08:35:12 metrics.py:455] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 147.7 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:59818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:17 logger.py:39] Received request chatcmpl-1587fb7a16184b24bc122d97a6c19f02: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|s|e\nn|p|r\nt|e|r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:17 engine.py:280] Added request chatcmpl-1587fb7a16184b24bc122d97a6c19f02.
INFO 03-02 08:35:17 metrics.py:455] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 146.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:55782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:21 logger.py:39] Received request chatcmpl-3c602777423b48f4917125229301dc68: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ns|l|c\np|e|a\ne|c|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:21 engine.py:280] Added request chatcmpl-3c602777423b48f4917125229301dc68.
INFO:     127.0.0.1:55766 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:22 logger.py:39] Received request chatcmpl-5dd9687a70be4544b2c50359aeb4afeb: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nc|t|r\ni|s|a\ng|e|t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14813, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:22 engine.py:280] Added request chatcmpl-5dd9687a70be4544b2c50359aeb4afeb.
INFO 03-02 08:35:22 metrics.py:455] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 144.8 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 16.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43408 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:23 logger.py:39] Received request chatcmpl-757530b0ef8243488fcf81abaab665b1: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ni|s|s\nv|y|a\ni|t|p\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14812, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:23 engine.py:280] Added request chatcmpl-757530b0ef8243488fcf81abaab665b1.
INFO:     127.0.0.1:51978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:24 logger.py:39] Received request chatcmpl-222f44482ef3440297ea3cb927b32f86: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nl|i|g\nn|t|h\ne|e|n\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:24 engine.py:280] Added request chatcmpl-222f44482ef3440297ea3cb927b32f86.
INFO:     127.0.0.1:55784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:26 logger.py:39] Received request chatcmpl-40407cf8d6724c5595c1f855c75322ca: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\ne|a|t\nr|g|h\nb|n|i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:26 engine.py:280] Added request chatcmpl-40407cf8d6724c5595c1f855c75322ca.
INFO 03-02 08:35:27 metrics.py:455] Avg prompt throughput: 148.8 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.
INFO 03-02 08:35:32 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 151.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 13.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:50818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:33 logger.py:39] Received request chatcmpl-02c942e3a307484cbbf770a0d144fd66: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nd|u|s\np|m|g\nl|i|n\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:33 engine.py:280] Added request chatcmpl-02c942e3a307484cbbf770a0d144fd66.
INFO:     127.0.0.1:43394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:35 logger.py:39] Received request chatcmpl-cccac85c1a4a4c2f9159447940762644: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nc|i|w\na|s|h\nl|m|i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14816, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:35 engine.py:280] Added request chatcmpl-cccac85c1a4a4c2f9159447940762644.
INFO:     127.0.0.1:50828 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:35 logger.py:39] Received request chatcmpl-5ccd749602114b1d8c31c7992c1c2e78: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nGame rules: A word with a length of 9, randomly select a starting point in a 3x3 square, and fill in the letters in the order they appear in the word, selecting consecutive positions to place them in the grid. Please identify the word in the square.\nThe square:\nr|e|m\ne|p|r\nr|f|o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14814, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-02 08:35:35 engine.py:280] Added request chatcmpl-5ccd749602114b1d8c31c7992c1c2e78.
INFO 03-02 08:35:37 metrics.py:455] Avg prompt throughput: 110.2 tokens/s, Avg generation throughput: 140.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:55794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:42 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 139.2 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 11.9%, CPU KV cache usage: 0.0%.
INFO 03-02 08:35:47 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 131.6 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:52 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 116.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 10.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:50832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:50836 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:35:57 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 85.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.8%, CPU KV cache usage: 0.0%.
INFO 03-02 08:36:02 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 57.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:36:07 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 52.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%.
INFO 03-02 08:36:12 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:36:17 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:40952 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-02 08:36:30 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 03-02 08:36:40 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 03-02 08:37:46 launcher.py:62] Shutting down FastAPI HTTP server.
INFO 03-02 08:37:46 multiproc_worker_utils.py:141] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=2620703)[0;0m INFO 03-02 08:37:46 multiproc_worker_utils.py:253] Worker exiting
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
/map-vepfs/miniconda3/envs/jiajun/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
