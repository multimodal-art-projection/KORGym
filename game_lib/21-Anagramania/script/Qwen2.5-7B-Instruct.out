INFO 02-27 07:00:02 __init__.py:207] Automatically detected platform cuda.
INFO 02-27 07:00:03 api_server.py:912] vLLM API server version 0.7.3
INFO 02-27 07:00:03 api_server.py:913] args: Namespace(host=None, port=9003, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='/map-vepfs/models/jiajun/Qwen/Qwen2.5-7B-Instruct', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=15000, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=['Qwen2.5-7B-Instruct'], qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False)
INFO 02-27 07:00:03 api_server.py:209] Started engine process with PID 1434725
INFO 02-27 07:00:22 __init__.py:207] Automatically detected platform cuda.
INFO 02-27 07:00:24 config.py:549] This model supports multiple tasks: {'reward', 'score', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 02-27 07:00:24 config.py:1382] Defaulting to use mp for distributed inference
INFO 02-27 07:00:49 config.py:549] This model supports multiple tasks: {'score', 'generate', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.
INFO 02-27 07:00:49 config.py:1382] Defaulting to use mp for distributed inference
INFO 02-27 07:00:49 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/map-vepfs/models/jiajun/Qwen/Qwen2.5-7B-Instruct', speculative_config=None, tokenizer='/map-vepfs/models/jiajun/Qwen/Qwen2.5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=15000, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen2.5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=True, 
WARNING 02-27 07:00:49 multiproc_worker_utils.py:300] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 02-27 07:00:49 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:49 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
INFO 02-27 07:00:52 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:52 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:53 utils.py:916] Found nccl from library libnccl.so.2
INFO 02-27 07:00:53 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:53 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 02-27 07:00:53 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:55 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
INFO 02-27 07:00:55 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
INFO 02-27 07:00:55 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_3a9724e9'), local_subscribe_port=36601, remote_subscribe_port=None)
INFO 02-27 07:00:55 model_runner.py:1110] Starting to load model /map-vepfs/models/jiajun/Qwen/Qwen2.5-7B-Instruct...
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:00:55 model_runner.py:1110] Starting to load model /map-vepfs/models/jiajun/Qwen/Qwen2.5-7B-Instruct...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:06<00:19,  6.38s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:14<00:14,  7.35s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:20<00:06,  6.97s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:27<00:00,  6.86s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:27<00:00,  6.91s/it]

INFO 02-27 07:01:23 model_runner.py:1115] Loading model weights took 7.1216 GB
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:23 model_runner.py:1115] Loading model weights took 7.1216 GB
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:31 worker.py:267] Memory profiling takes 8.16 seconds
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:31 worker.py:267] the current vLLM instance can use total_gpu_memory (79.35GiB) x gpu_memory_utilization (0.95) = 75.38GiB
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:31 worker.py:267] model weights take 7.12GiB; non_torch_memory takes 1.02GiB; PyTorch activation peak memory takes 1.30GiB; the rest of the memory reserved for KV Cache is 65.94GiB.
INFO 02-27 07:01:31 worker.py:267] Memory profiling takes 8.25 seconds
INFO 02-27 07:01:31 worker.py:267] the current vLLM instance can use total_gpu_memory (79.35GiB) x gpu_memory_utilization (0.95) = 75.38GiB
INFO 02-27 07:01:31 worker.py:267] model weights take 7.12GiB; non_torch_memory takes 1.02GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 65.75GiB.
INFO 02-27 07:01:32 executor_base.py:111] # cuda blocks: 153903, # CPU blocks: 9362
INFO 02-27 07:01:32 executor_base.py:116] Maximum concurrency for 15000 tokens per request: 164.16x
INFO 02-27 07:01:35 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s][1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:35 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.73it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.89it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.91it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.98it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:14,  2.01it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  2.02it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:13,  2.01it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.02it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.98it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.98it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.98it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.01it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  2.01it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.99it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.99it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.02it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.00it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  2.01it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.03it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  2.03it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.04it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.99it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.99it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.97it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  2.01it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.02it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.98it/s][1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:53 custom_all_reduce.py:226] Registering 1995 cuda graph addresses
Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.26it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]
INFO 02-27 07:01:53 custom_all_reduce.py:226] Registering 1995 cuda graph addresses
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:01:53 model_runner.py:1562] Graph capturing finished in 19 secs, took 0.23 GiB
INFO 02-27 07:01:53 model_runner.py:1562] Graph capturing finished in 19 secs, took 0.23 GiB
INFO 02-27 07:01:53 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 30.58 seconds
INFO 02-27 07:01:56 api_server.py:958] Starting vLLM API server on http://0.0.0.0:9003
INFO 02-27 07:01:56 launcher.py:23] Available routes are:
INFO 02-27 07:01:56 launcher.py:31] Route: /openapi.json, Methods: HEAD, GET
INFO 02-27 07:01:56 launcher.py:31] Route: /docs, Methods: HEAD, GET
INFO 02-27 07:01:56 launcher.py:31] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 02-27 07:01:56 launcher.py:31] Route: /redoc, Methods: HEAD, GET
INFO 02-27 07:01:56 launcher.py:31] Route: /health, Methods: GET
INFO 02-27 07:01:56 launcher.py:31] Route: /ping, Methods: POST, GET
INFO 02-27 07:01:56 launcher.py:31] Route: /tokenize, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /detokenize, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/models, Methods: GET
INFO 02-27 07:01:56 launcher.py:31] Route: /version, Methods: GET
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/chat/completions, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/completions, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/embeddings, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /pooling, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /score, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/score, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/audio/transcriptions, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /rerank, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v1/rerank, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /v2/rerank, Methods: POST
INFO 02-27 07:01:56 launcher.py:31] Route: /invocations, Methods: POST
INFO:     Started server process [1430179]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 02-27 07:02:49 chat_utils.py:332] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-31fe89dbda3c4d3ba24dcda573d79230: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ni b l r c v o e r y a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-53471d25253247bbb0c90bc45169d9b5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nm r e d t e o a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-fc7c816c8ba34fc39be5f731572a0b66: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns u r b b i u a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-31fe89dbda3c4d3ba24dcda573d79230.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-53471d25253247bbb0c90bc45169d9b5.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-fc7c816c8ba34fc39be5f731572a0b66.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-c2deb67bfbb64c169087cae931d5a660: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nr o k y c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-044545fffd49438caa47834ac2202e9b: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns g p u n i o t p r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-f187978319694a45872d6039e26ed180: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nb u g y g\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-b0076bb8d4c741fdb2c169175538caee: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ne r e h t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 logger.py:39] Received request chatcmpl-fe1743c70a4d4dd590a37da4b66ba45a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nd m g a i r a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14860, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-c2deb67bfbb64c169087cae931d5a660.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-044545fffd49438caa47834ac2202e9b.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-f187978319694a45872d6039e26ed180.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-b0076bb8d4c741fdb2c169175538caee.
INFO 02-27 07:02:49 engine.py:280] Added request chatcmpl-fe1743c70a4d4dd590a37da4b66ba45a.
INFO:     127.0.0.1:58204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-c540cbf7e1174979ae41d69c26352235: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\na g g i n\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-c540cbf7e1174979ae41d69c26352235.
INFO:     127.0.0.1:58188 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-784fd8ae4140448299038e4838e75b7c: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns l n a i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-784fd8ae4140448299038e4838e75b7c.
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-10494e23bb664c7cadd525d1b49b8fcc: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np i g r n i a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14860, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-10494e23bb664c7cadd525d1b49b8fcc.
INFO:     127.0.0.1:58208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-f617144d92b541629512d71ad769e65f: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nk t i t e n\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-f617144d92b541629512d71ad769e65f.
INFO:     127.0.0.1:58180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-012a8a7bbd6645e2a58bc2897e027310: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nc e b a c o e n v l i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-012a8a7bbd6645e2a58bc2897e027310.
INFO:     127.0.0.1:58212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:50 logger.py:39] Received request chatcmpl-30fcb5d4e30a41c989c50b12a4abaf3f: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ne b m d e\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:50 engine.py:280] Added request chatcmpl-30fcb5d4e30a41c989c50b12a4abaf3f.
INFO:     127.0.0.1:58182 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-14dbba14fcfb42de8da0728d89f9cc38: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nc e e m r y n o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-14dbba14fcfb42de8da0728d89f9cc38.
INFO:     127.0.0.1:58226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-6a674117cf1845b8b7603d0764c654f5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns t e m m e i o\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-6a674117cf1845b8b7603d0764c654f5.
INFO:     127.0.0.1:54280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-401aeb6795564d7d94fa867e2d07622b: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nm n t i s u e a d i n n r d g s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14851, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-401aeb6795564d7d94fa867e2d07622b.
INFO:     127.0.0.1:58242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-1a4da026f0814238a66970e0f4465cad: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np a e l a t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-1a4da026f0814238a66970e0f4465cad.
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-e3698d843ce447ba8f9259fb681b0e53: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ni n t u t o n l r c i a s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14854, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-e3698d843ce447ba8f9259fb681b0e53.
INFO:     127.0.0.1:54296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-35eaa922069f4adba6ca03664d6632ee: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns m r t o n s a p\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14858, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-35eaa922069f4adba6ca03664d6632ee.
INFO:     127.0.0.1:54264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-5289e534ea0f42e48b4b584a91fb9a0d: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nv t e e d n a t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-5289e534ea0f42e48b4b584a91fb9a0d.
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-f605c2cca5194a628c5bbd9b0ac6be08: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np o r n e e v t n i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-f605c2cca5194a628c5bbd9b0ac6be08.
INFO:     127.0.0.1:54326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-9ea7fe2222224e9a936980e5e15a0fa4: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np c u y i o t s r i m\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-9ea7fe2222224e9a936980e5e15a0fa4.
INFO:     127.0.0.1:54330 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:51 logger.py:39] Received request chatcmpl-d6ad7a1bb8914dce9d5e7f56d47c62cf: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\na d e c t i c r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:51 engine.py:280] Added request chatcmpl-d6ad7a1bb8914dce9d5e7f56d47c62cf.
INFO 02-27 07:02:51 metrics.py:455] Avg prompt throughput: 648.4 tokens/s, Avg generation throughput: 233.5 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-cce902e0682549c6952bf3ca5bfc7f5a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ni c n o a t n v o i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-cce902e0682549c6952bf3ca5bfc7f5a.
INFO:     127.0.0.1:54356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-fcf9fef3d252424a81d4d06fd1571b44: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np e t o m o r r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-fcf9fef3d252424a81d4d06fd1571b44.
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-edaa86ae4f6146a594fdb00af6d794d1: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nf e a e l s s c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-edaa86ae4f6146a594fdb00af6d794d1.
INFO:     127.0.0.1:54404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-42c9814b39d246309c27ad1a4b90a564: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nm h e i e o u t p c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-42c9814b39d246309c27ad1a4b90a564.
INFO:     127.0.0.1:54420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-68deebbb9f174849ac111ecaf67dbad7: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nd v i e y e l r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-68deebbb9f174849ac111ecaf67dbad7.
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-4ec12c4c4b3247a7a9b4ef2fe5fd483a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nm u l e o c i s y u l t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14855, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-4ec12c4c4b3247a7a9b4ef2fe5fd483a.
INFO:     127.0.0.1:54390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:52 logger.py:39] Received request chatcmpl-e7b5f6773cd344feabf6cf4cd1d2def3: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nk t h p e u c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14860, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:52 engine.py:280] Added request chatcmpl-e7b5f6773cd344feabf6cf4cd1d2def3.
INFO:     127.0.0.1:54442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-9db5aa5d038947359c3087126114be35: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nl d r a e e\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-9db5aa5d038947359c3087126114be35.
INFO:     127.0.0.1:54426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-e8615e44c461411bbdfaa4f2be7e6b7f: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ne o x s e p\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-e8615e44c461411bbdfaa4f2be7e6b7f.
INFO:     127.0.0.1:54452 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-2c879171e07e44009dc88bd9209113ad: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nt o h i r d y\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14860, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-2c879171e07e44009dc88bd9209113ad.
INFO:     127.0.0.1:54472 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-c993a062e7304c25a50e002178189a8c: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nc k c s e o l w i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14858, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-c993a062e7304c25a50e002178189a8c.
INFO:     127.0.0.1:54490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-4442687e555c4fcbb2215968e071da95: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nr n a i o z t l e i a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-4442687e555c4fcbb2215968e071da95.
INFO:     127.0.0.1:54526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:53 logger.py:39] Received request chatcmpl-163dae9f1e3547cd93a45ccc51198a13: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nm a m d e a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:53 engine.py:280] Added request chatcmpl-163dae9f1e3547cd93a45ccc51198a13.
INFO:     127.0.0.1:54534 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-3cc534c7934240e4a8bb8e15e033b9e5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\na u e q c y d a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14859, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-3cc534c7934240e4a8bb8e15e033b9e5.
INFO:     127.0.0.1:54372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-f296dd084b7648a3bdd1b2937411c02b: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nl e a t x\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-f296dd084b7648a3bdd1b2937411c02b.
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-72d86440936c4ecd8f4caebca594e09b: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nd c e t i a t\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14860, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-72d86440936c4ecd8f4caebca594e09b.
INFO:     127.0.0.1:54468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-c961e91271b04262a38ec5bc2de32219: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nh v l e a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-c961e91271b04262a38ec5bc2de32219.
INFO:     127.0.0.1:54514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-9fe81f41903b48709ea00459d30f32f7: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nc u y u i o l r s\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14858, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-9fe81f41903b48709ea00459d30f32f7.
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-3001cbdb07ca4a51902b0efb10f189a5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\ns n a g l\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-3001cbdb07ca4a51902b0efb10f189a5.
INFO:     127.0.0.1:54528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-dd3d5f0af4ec43ba96938cf438bd455a: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np t r p i a i n a t c\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-dd3d5f0af4ec43ba96938cf438bd455a.
INFO:     127.0.0.1:54484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-069949e9b8be4c08ab550dbee02e9fbc: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nw k l e a r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14861, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-069949e9b8be4c08ab550dbee02e9fbc.
INFO 02-27 07:02:54 logger.py:39] Received request chatcmpl-8f74bc39eae94a3f909cc0a66bad0043: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nd c s u e b t i r n a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14856, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:54 engine.py:280] Added request chatcmpl-8f74bc39eae94a3f909cc0a66bad0043.
INFO:     127.0.0.1:54536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:55 logger.py:39] Received request chatcmpl-db3266d8240c41c1832b9596d827d8bd: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nc s e t m i m t i s h a r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14854, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:55 engine.py:280] Added request chatcmpl-db3266d8240c41c1832b9596d827d8bd.
INFO:     127.0.0.1:54552 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:55 logger.py:39] Received request chatcmpl-e5b29caaaf9e44ccabaa4400a7416cd5: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\nb d e k a\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:55 engine.py:280] Added request chatcmpl-e5b29caaaf9e44ccabaa4400a7416cd5.
INFO:     127.0.0.1:54582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:02:55 logger.py:39] Received request chatcmpl-c97e01b3a20f4494a5a42926b847bd00: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\np r e e t a e t p r\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:55 engine.py:280] Added request chatcmpl-c97e01b3a20f4494a5a42926b847bd00.
INFO 02-27 07:02:55 logger.py:39] Received request chatcmpl-9d1a1b657ee14c09836e93b7c3ceee2f: prompt: "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\n\nYou are a good game problem-solver, I'll give you a question.\nYour task is:\n- First, answer the question.\n- Second, output the answer in the required format. The last line of your response should be in the following format: 'Answer: $YOUR_ANSWER' (without quotes), where YOUR_ANSWER is your final answer to the question,e.g.'Answer: happy'\nPlease move the letters to get to the original word for this anagram. The first letter is already correct.\na p e e t c r p a i\n<|im_end|>\n<|im_start|>assistant\n", params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=14857, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 02-27 07:02:55 engine.py:280] Added request chatcmpl-9d1a1b657ee14c09836e93b7c3ceee2f.
INFO:     127.0.0.1:54590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54572 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 02-27 07:03:06 metrics.py:455] Avg prompt throughput: 260.3 tokens/s, Avg generation throughput: 195.1 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 02-27 07:03:16 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 02-27 07:03:34 launcher.py:62] Shutting down FastAPI HTTP server.
INFO 02-27 07:03:34 multiproc_worker_utils.py:141] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=1441566)[0;0m INFO 02-27 07:03:34 multiproc_worker_utils.py:253] Worker exiting
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
/map-vepfs/miniconda3/envs/jiajun/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
